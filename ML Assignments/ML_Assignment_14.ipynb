{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a5ac34",
   "metadata": {},
   "source": [
    "**1. What is the concept of supervised learning? What is the significance of the name?**  \n",
    "Supervised learning is a type of machine learning where a model is trained on labeled data. The term 'supervised' indicates that the learning process is guided or supervised by providing the model with the correct answers (labels).\n",
    "\n",
    "**2. In the hospital sector, offer an example of supervised learning.**  \n",
    "Diagnosing diseases by analyzing medical images can be an example. The machine is trained with labeled images (e.g., 'cancerous' or 'not cancerous') and once trained, can predict diagnoses for new, unseen images.\n",
    "\n",
    "**3. Give three supervised learning examples.**  \n",
    "- Email spam detection (spam or not spam).\n",
    "- Handwritten digit recognition.\n",
    "- Predicting house prices based on features like size and location.\n",
    "\n",
    "**4. In supervised learning, what are classification and regression?**  \n",
    "Classification involves predicting discrete labels (e.g., 'cat' or 'dog'), while regression deals with predicting continuous values (e.g., predicting house prices).\n",
    "\n",
    "**5. Give some popular classification algorithms as examples.**  \n",
    "- Logistic Regression.\n",
    "- Support Vector Machines (SVM).\n",
    "- K-Nearest Neighbors (kNN).\n",
    "\n",
    "**6. Briefly describe the SVM model.**  \n",
    "The Support Vector Machine (SVM) model is a powerful classification technique that tries to find the best hyperplane or decision boundary that separates data of different classes.\n",
    "\n",
    "**7. In SVM, what is the cost of misclassification?**  \n",
    "The cost of misclassification in SVM is represented by a slack variable and is determined by the \"C\" parameter. A larger value of C results in a smaller-margin hyperplane if that hyperplane does a better job of correctly classifying all the training points.\n",
    "\n",
    "**8. In the SVM model, define Support Vectors.**  \n",
    "Support Vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Removing a support vector can change the position of the decision boundary.\n",
    "\n",
    "**9. In the SVM model, define the kernel.**  \n",
    "A kernel in SVM is a function used to transform the data so that it can be separated by a hyperplane in a higher-dimensional space. Popular kernels include linear, polynomial, and radial basis function (RBF).\n",
    "\n",
    "**10. What are the factors that influence SVM's effectiveness?**  \n",
    "Factors include the choice of kernel, the soft margin parameter C, the nature of the data, and the specific kernel parameters.\n",
    "\n",
    "**11. What are the benefits of using the SVM model?**  \n",
    "- Effective in high-dimensional spaces.\n",
    "- Suitable for cases where margin of separation is important.\n",
    "- Memory efficient as it uses only a subset of training points.\n",
    "\n",
    "**12. What are the drawbacks of using the SVM model?**  \n",
    "- Not suitable for large datasets due to high training time.\n",
    "- Less effective on noisier datasets with overlapping classes.\n",
    "\n",
    "**13. Notes should be written on:**  \n",
    "**1. The kNN algorithm has a validation flaw.**  \n",
    "If k is too small, the algorithm might be overly sensitive to noise in the dataset. If k is too large, the neighborhood might include points from other classes.  \n",
    "**2. In the kNN algorithm, the k value is chosen.**  \n",
    "Choosing the right k is crucial. It's typically chosen via cross-validation where different k values are tried and the one that performs best on validation data is chosen.  \n",
    "**3. A decision tree with inductive bias**  \n",
    "Inductive bias in decision trees refers to the set of assumptions that the learner uses to predict outputs given inputs it hasn't encountered.\n",
    "\n",
    "**14. What are some of the benefits of the kNN algorithm?**  \n",
    "- Simple to understand and implement.\n",
    "- No training phase, making it faster for training.\n",
    "- Naturally handles multi-class cases.\n",
    "\n",
    "**15. What are some of the kNN algorithm's drawbacks?**  \n",
    "- Computationally expensive during testing.\n",
    "- Sensitive to irrelevant features.\n",
    "- Performance degrades with high-dimension data.\n",
    "\n",
    "**16. Explain the decision tree algorithm in a few words.**  \n",
    "A decision tree splits data into subsets based on the value of input features. This is done recursively, resulting in a tree-like model of decisions.\n",
    "\n",
    "**17. What is the difference between a node and a leaf in a decision tree?**  \n",
    "A node in a decision tree tests a particular attribute and branches data accordingly, while a leaf represents an output (or decision) and does not split further.\n",
    "\n",
    "**18. What is a decision tree's entropy?**  \n",
    "Entropy measures the impurity or randomness in data. In decision trees, it's used to determine how a feature splits data.\n",
    "\n",
    "**19. In a decision tree, define knowledge gain.**  \n",
    "Knowledge gain (or Information gain) is the reduction in entropy achieved by partitioning data based on a feature. It helps in selecting the best feature to split upon.\n",
    "\n",
    "**20. Choose three advantages of the decision tree approach and write them down.**  \n",
    "- Easy to understand and interpret.\n",
    "- Requires little data preprocessing.\n",
    "- Capable of handling both numerical and categorical data.\n",
    "\n",
    "**21. Make a list of three flaws in the decision tree process.**  \n",
    "- Prone to overfitting, especially with deep trees.\n",
    "- Sensitive to small changes in data.\n",
    "- Biased to features with more levels.\n",
    "\n",
    "**22. Briefly describe the random forest model.**  \n",
    "A random forest is an ensemble of decision trees, typically trained with the \"bagging\" method. It aims to improve the performance and prevent overfitting by averaging or taking the majority vote from individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7ae2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
