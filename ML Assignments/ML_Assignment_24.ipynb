{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Question: What is your definition of clustering? What are a few\n",
    "clustering algorithms you might think of?**\n",
    "\n",
    "Answer: Clustering is a process of grouping similar data points or\n",
    "objects together in such a way that items in the same group are more\n",
    "similar to each other than they are to items in other groups. Some\n",
    "clustering algorithms include K-Means, Hierarchical Clustering, DBSCAN\n",
    "(Density-Based Spatial Clustering of Applications with Noise), and\n",
    "Gaussian Mixture Models.\n",
    "\n",
    "**2. Question: What are some of the most popular clustering algorithm\n",
    "applications?**\n",
    "\n",
    "Answer: Popular clustering algorithm applications include:\n",
    "\n",
    "\\- Customer Segmentation: Grouping customers based on purchasing\n",
    "behavior for targeted marketing strategies.\n",
    "\n",
    "\\- Image Segmentation: Dividing an image into meaningful regions for\n",
    "object recognition and computer vision.\n",
    "\n",
    "\\- Document Clustering: Organizing documents by topics for efficient\n",
    "retrieval and content organization.\n",
    "\n",
    "\\- Social Network Analysis: Identifying communities or groups within a\n",
    "network of users.\n",
    "\n",
    "\\- Anomaly Detection: Identifying rare or unusual instances in datasets,\n",
    "such as fraudulent transactions.\n",
    "\n",
    "**3. Question: When using K-Means, describe two strategies for selecting\n",
    "the appropriate number of clusters.**\n",
    "\n",
    "Answer: Two strategies for selecting the appropriate number of clusters\n",
    "in K-Means are:\n",
    "\n",
    "\\- Elbow Method: Plot the sum of squared distances (SSE) against the\n",
    "number of clusters. Look for the point where the SSE starts to decrease\n",
    "less steeply, resembling an \"elbow.\" This point indicates a good balance\n",
    "between model complexity and fitting the data.\n",
    "\n",
    "\\- Silhouette Score: Calculate the silhouette score for different\n",
    "cluster numbers. The silhouette score measures how similar an object is\n",
    "to its own cluster compared to other clusters. A higher silhouette score\n",
    "suggests better-defined clusters.\n",
    "\n",
    "**4. Question: What is mark propagation and how does it work? Why would\n",
    "you do it, and how would you do it?**\n",
    "\n",
    "Answer: Mark propagation, also known as label propagation, is a\n",
    "semi-supervised learning technique used to assign labels to unlabeled\n",
    "data points based on the labels of neighboring points. It works by\n",
    "propagating known labels through the data graph. This can be useful when\n",
    "you have a small labeled dataset and a large unlabeled dataset, as it\n",
    "allows you to leverage the labeled data to infer labels for the\n",
    "unlabeled data points.\n",
    "\n",
    "**5. Question: Provide two examples of clustering algorithms that can\n",
    "handle large datasets. And two that look for high-density areas?**\n",
    "\n",
    "Answer:\n",
    "\n",
    "\\- Large Datasets: DBSCAN (Density-Based Spatial Clustering of\n",
    "Applications with Noise) and Mini-Batch K-Means are suitable for large\n",
    "datasets. DBSCAN identifies clusters based on density and can handle\n",
    "noise well. Mini-Batch K-Means is a variation of K-Means that processes\n",
    "data in smaller batches, making it more scalable.\n",
    "\n",
    "\\- High-Density Areas: DBSCAN is again relevant here, as it identifies\n",
    "clusters based on regions of high data point density. OPTICS (Ordering\n",
    "Points to Identify the Clustering Structure) is another algorithm that\n",
    "finds density-based clusters while allowing flexibility in the density\n",
    "threshold.\n",
    "\n",
    "**6. Question: Can you think of a scenario in which constructive\n",
    "learning will be advantageous? How can you go about putting it into\n",
    "action?**\n",
    "\n",
    "Answer: Constructive learning is useful when new classes or concepts\n",
    "emerge over time. For example, in an online fraud detection system, new\n",
    "types of fraudulent activities might evolve. To put constructive\n",
    "learning into action, start with a base model trained on existing data,\n",
    "and as new data arrives, use the base model to identify potential\n",
    "instances of the new concept. Label these instances and incorporate them\n",
    "into the training data to adapt the model.\n",
    "\n",
    "**7. Question: How do you tell the difference between anomaly and\n",
    "novelty detection?**\n",
    "\n",
    "Answer: Anomaly detection focuses on identifying instances that deviate\n",
    "significantly from the norm or expected behavior, regardless of whether\n",
    "they are new or previously seen. Novelty detection, on the other hand,\n",
    "is concerned specifically with identifying instances that are new and\n",
    "unseen during training, regardless of whether they are anomalous or not.\n",
    "\n",
    "**8. Question: What is a Gaussian mixture, and how does it work? What\n",
    "are some of the things you can do about it?**\n",
    "\n",
    "Answer: A Gaussian mixture is a probabilistic model that assumes that\n",
    "the data is generated from a mixture of several Gaussian (normal)\n",
    "distributions. Each Gaussian component represents a cluster. In Gaussian\n",
    "mixture models (GMMs), the goal is to estimate the parameters of these\n",
    "Gaussian distributions. GMMs can capture complex data distributions and\n",
    "provide soft clustering assignments (probabilities of belonging to each\n",
    "cluster). Techniques to improve GMM performance include increasing the\n",
    "number of components, initializing with K-Means, and using\n",
    "regularization to prevent overfitting.\n",
    "\n",
    "**9. Question: When using a Gaussian mixture model, can you name two\n",
    "techniques for determining the correct number of clusters?**\n",
    "\n",
    "Answer: Certainly! Two techniques for determining the correct number of\n",
    "clusters when using a Gaussian mixture model are:\n",
    "\n",
    "1\\. BIC (Bayesian Information Criterion): BIC is a statistical criterion\n",
    "that balances model fit and complexity. It penalizes models with more\n",
    "parameters, thus discouraging overfitting. The goal is to find the model\n",
    "with the lowest BIC value, which indicates a good trade-off between\n",
    "fitting the data and model complexity.\n",
    "\n",
    "2\\. AIC (Akaike Information Criterion): AIC is another criterion used\n",
    "for model selection, similar to BIC. It measures the trade-off between\n",
    "the goodness of fit and the number of parameters in the model. Like BIC,\n",
    "a lower AIC value suggests a better-fitting model.\n",
    "\n",
    "Both BIC and AIC provide guidelines for selecting the appropriate number\n",
    "of Gaussian components (clusters) in a Gaussian mixture model, helping\n",
    "to avoid both underfitting and overfitting."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
