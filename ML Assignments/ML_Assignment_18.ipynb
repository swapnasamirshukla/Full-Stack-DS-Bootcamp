{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Question: What is the difference between supervised and\n",
    "unsupervised learning? Give some examples to illustrate your point.**\n",
    "\n",
    "Answer: Supervised learning involves training a model on a labeled\n",
    "dataset where the algorithm learns to map input data to corresponding\n",
    "output labels. Examples include spam email classification (input: email\n",
    "content, output: spam/ham label) and image recognition (input: image\n",
    "pixels, output: object label). Unsupervised learning, on the other hand,\n",
    "deals with finding patterns or structures in data without labeled\n",
    "outputs. An example is clustering customer data into segments based on\n",
    "purchasing behavior without predefined categories.\n",
    "\n",
    "**2. Question: Mention a few unsupervised learning applications.**\n",
    "\n",
    "Answer: Unsupervised learning finds applications in various fields,\n",
    "including:\n",
    "\n",
    "\\- Clustering: Grouping similar data points, like customer segmentation\n",
    "for targeted marketing.\n",
    "\n",
    "\\- Dimensionality Reduction: Reducing the number of features while\n",
    "retaining essential information, like in principal component analysis.\n",
    "\n",
    "\\- Anomaly Detection: Identifying rare or unusual instances, such as\n",
    "fraud detection in financial transactions.\n",
    "\n",
    "\\- Topic Modeling: Extracting underlying themes in text data, aiding in\n",
    "content organization.\n",
    "\n",
    "**3. Question: What are the three main types of clustering methods?\n",
    "Briefly describe the characteristics of each.**\n",
    "\n",
    "Answer: The three main types of clustering methods are:\n",
    "\n",
    "\\- Hierarchical Clustering: Creates a tree-like structure of clusters,\n",
    "where data points are grouped based on similarity. It can be divisive\n",
    "(top-down) or agglomerative (bottom-up).\n",
    "\n",
    "\\- Partitioning Clustering: Divides data into distinct non-overlapping\n",
    "clusters. K-means is a common example.\n",
    "\n",
    "\\- Density-Based Clustering: Identifies clusters based on areas of high\n",
    "data point density. DBSCAN is an example of this method.\n",
    "\n",
    "**4. Question: Explain how the k-means algorithm determines the\n",
    "consistency of clustering.**\n",
    "\n",
    "Answer: The k-means algorithm determines the consistency of clustering\n",
    "by minimizing the sum of squared distances between data points and their\n",
    "respective cluster centroids. It iteratively assigns data points to the\n",
    "nearest centroid and updates the centroids based on the mean of the\n",
    "points in each cluster. The process continues until convergence,\n",
    "ensuring that data points are grouped with their nearest neighbors in a\n",
    "consistent manner.\n",
    "\n",
    "**5. Question: With a simple illustration, explain the key difference\n",
    "between the k-means and k-medoids algorithms.**\n",
    "\n",
    "Answer: In k-means, the cluster center is the mean of the data points in\n",
    "that cluster. In k-medoids, the cluster center is an actual data point\n",
    "from the cluster. This makes k-medoids more robust to outliers because\n",
    "it selects a representative point that may not be influenced by extreme\n",
    "values, whereas k-means can be sensitive to outliers due to its use of\n",
    "means.\n",
    "\n",
    "**6. Question: What is a dendrogram, and how does it work? Explain how\n",
    "to do it.**\n",
    "\n",
    "Answer: A dendrogram is a tree-like diagram used to represent the\n",
    "arrangement of data points in hierarchical clustering. It illustrates\n",
    "the merging of clusters as the algorithm progresses. To create a\n",
    "dendrogram, you start by placing each data point in its own cluster.\n",
    "Then, you iteratively merge the two closest clusters, updating the\n",
    "dendrogram. The vertical axis represents the dissimilarity or distance\n",
    "between clusters, and the horizontal axis represents the data points or\n",
    "clusters being merged.\n",
    "\n",
    "**7. Question: What exactly is SSE? What role does it play in the\n",
    "k-means algorithm?**\n",
    "\n",
    "Answer: SSE stands for Sum of Squared Errors. In the context of k-means,\n",
    "it is the sum of the squared distances between each data point and its\n",
    "assigned cluster centroid. SSE measures the compactness of the clusters\n",
    "and their separation. The k-means algorithm aims to minimize SSE by\n",
    "iteratively adjusting cluster centroids and reassigning data points to\n",
    "clusters, resulting in more coherent and tight clusters.\n",
    "\n",
    "**8. Question: With a step-by-step algorithm, explain the k-means\n",
    "procedure.**\n",
    "\n",
    "Answer: Sure, here's a simplified step-by-step explanation of the\n",
    "k-means algorithm:\n",
    "\n",
    "1\\. Choose the number of clusters (k) and initialize k cluster centroids\n",
    "randomly.\n",
    "\n",
    "2\\. Assign each data point to the nearest centroid, forming k clusters.\n",
    "\n",
    "3\\. Recalculate the centroids as the mean of data points in each\n",
    "cluster.\n",
    "\n",
    "4\\. Repeat steps 2 and 3 until convergence (when centroids don't change\n",
    "significantly or a fixed number of iterations is reached).\n",
    "\n",
    "**9. Question: In the sense of hierarchical clustering, define the terms\n",
    "single link and complete link.**\n",
    "\n",
    "Answer: In hierarchical clustering:\n",
    "\n",
    "\\- Single Link (Minimum Linkage): Measures the distance between two\n",
    "clusters based on the shortest distance between any two points in the\n",
    "clusters. It can lead to chaining effects.\n",
    "\n",
    "\\- Complete Link (Maximum Linkage): Measures the distance between two\n",
    "clusters based on the maximum distance between any two points in the\n",
    "clusters. It can be sensitive to outliers.\n",
    "\n",
    "**10. Question: How does the apriori concept aid in the reduction of\n",
    "measurement overhead in a business basket analysis? Give an example to\n",
    "demonstrate your point.**\n",
    "\n",
    "Answer: The apriori concept is used in association rule mining, like in\n",
    "business basket analysis. It helps identify significant relationships\n",
    "between items that frequently co-occur in transactions, allowing\n",
    "businesses to optimize their product placements and promotions. By\n",
    "setting a minimum support threshold, the apriori algorithm focuses on\n",
    "mining associations that occur above a certain frequency, reducing the\n",
    "measurement overhead of considering every possible combination.\n",
    "\n",
    "Example: In a grocery store, the apriori algorithm might find that\n",
    "customers who buy cereal also tend to buy milk with a support of 0.6\n",
    "(60% of transactions). This suggests a strong association between these\n",
    "items, allowing the store to strategically place them together or offer\n",
    "bundled discounts."
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
