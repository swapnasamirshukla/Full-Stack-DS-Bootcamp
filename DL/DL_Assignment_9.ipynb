{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e951a66",
   "metadata": {},
   "source": [
    "### 1. What are the main tasks that autoencoders are used for?\n",
    "\n",
    "Autoencoders are primarily used for:\n",
    "- **Dimensionality Reduction**: They can reduce the number of dimensions without losing much information.\n",
    "- **Anomaly Detection**: They can identify data points that don't conform to the expected behavior.\n",
    "- **Data Denoising**: They can reconstruct clean data from noisy data.\n",
    "- **Feature Learning**: They can learn useful features from raw data which can be used for other machine learning tasks.\n",
    "- **Data Generation**: Some types of autoencoders like Variational Autoencoders can also generate new data that's similar to the training data.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Suppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?\n",
    "\n",
    "Autoencoders can help by learning useful features from the large set of unlabeled data. These features can then be used to train a more effective classifier on the smaller labeled dataset.\n",
    "\n",
    "**Procedure**:\n",
    "1. Train an autoencoder on the larger unlabeled dataset.\n",
    "2. Use the encoder part of the autoencoder to transform both the labeled and unlabeled datasets into a lower-dimensional feature space.\n",
    "3. Train a classifier on the transformed labeled dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder? How can you evaluate the performance of an autoencoder?\n",
    "\n",
    "A perfect reconstruction is not necessarily an indication of a good autoencoder. The main task is to learn useful features, and a too-perfect reconstruction may imply overfitting.\n",
    "\n",
    "**Evaluation**:\n",
    "- **Reconstruction Error**: Lower error usually indicates better learning, but not always.\n",
    "- **Downstream Tasks**: If the features learned by the autoencoder improve the performance on other tasks, that's usually a good sign.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. What are undercomplete and overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?\n",
    "\n",
    "- **Undercomplete Autoencoders**: The dimensionality of the hidden layer is less than the input layer. \n",
    "  - **Main Risk**: May lose important information during encoding.\n",
    "  \n",
    "- **Overcomplete Autoencoders**: The dimensionality of the hidden layer is greater than or equal to the input layer.\n",
    "  - **Main Risk**: May fail to learn useful features and just learn to copy the input to the output, leading to overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. How do you tie weights in a stacked autoencoder? What is the point of doing so?\n",
    "\n",
    "In a stacked autoencoder, the weights of the decoding layers are set as the transpose of the weights of the corresponding encoding layers. \n",
    "\n",
    "**Point of Doing So**:\n",
    "- It reduces the number of parameters in the model, making it easier to train and less prone to overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. What is a generative model? Can you name a type of generative autoencoder?\n",
    "\n",
    "A generative model is capable of generating new data that is similar to the training data. \n",
    "\n",
    "**Generative Autoencoder**:\n",
    "- Variational Autoencoder (VAE)\n",
    "\n",
    "---\n",
    "\n",
    "### 7. What is a GAN? Can you name a few tasks where GANs can shine?\n",
    "\n",
    "A Generative Adversarial Network (GAN) consists of two networks: a generator that creates fake data and a discriminator that tries to distinguish between real and fake data.\n",
    "\n",
    "**Tasks Where GANs Shine**:\n",
    "- Image Generation\n",
    "- Style Transfer\n",
    "- Data Augmentation\n",
    "- Super-Resolution\n",
    "\n",
    "---\n",
    "\n",
    "### 8. What are the main difficulties when training GANs?\n",
    "\n",
    "- **Mode Collapse**: The generator collapses to a state where it generates the same or very similar data points over and over again.\n",
    "- **Training Instability**: GANs can be difficult to train, and small changes in the model or parameters can lead to different results.\n",
    "- **Hyperparameter Sensitivity**: They are highly sensitive to the choice of hyperparameters.\n",
    "- **Evaluation Difficulty**: It's challenging to evaluate how well a GAN has been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f3ed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
