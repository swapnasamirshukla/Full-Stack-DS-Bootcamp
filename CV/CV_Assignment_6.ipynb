{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e292cc5",
   "metadata": {},
   "source": [
    "**Question 1: What is the difference between TRAINABLE and NON-TRAINABLE PARAMETERS?**\n",
    "\n",
    "- **Trainable Parameters**: These are the weights and biases that the neural network adjusts during training to minimize the loss function. They are learned through backpropagation and optimization algorithms.\n",
    "- **Non-Trainable Parameters**: These are values that are fixed and not updated during training. For example, parameters in certain layers like Batch Normalization (running mean and variance) or in pre-trained layers of transfer learning.\n",
    "\n",
    "**Question 2: In the CNN architecture, where does the DROPOUT LAYER go?**\n",
    "\n",
    "The Dropout layer is typically inserted after a fully connected layer. It randomly \"drops out\" a fraction of neurons during training, which helps prevent overfitting by reducing the network's reliance on specific neurons.\n",
    "\n",
    "**Question 3: What is the optimal number of hidden layers to stack?**\n",
    "\n",
    "There is no one-size-fits-all answer. The optimal number of hidden layers depends on the complexity of the problem, the amount of data, and other architectural choices. Starting with a small number of layers and gradually increasing complexity while monitoring performance is a common approach.\n",
    "\n",
    "**Question 4: In each layer, how many secret units or filters should there be?**\n",
    "\n",
    "The number of units or filters in each layer is a hyperparameter that requires experimentation. Generally, more complex problems might require more units/filters, but it's best determined through trial and error.\n",
    "\n",
    "**Question 5: What should your initial learning rate be?**\n",
    "\n",
    "The initial learning rate can vary depending on the problem and the optimization algorithm used. Common strategies involve using small learning rates (e.g., 0.001) and gradually adjusting based on learning rate schedulers or annealing.\n",
    "\n",
    "**Question 6: What do you do with the activation function?**\n",
    "\n",
    "Activation functions introduce non-linearity to the network, enabling it to learn complex relationships in data. Common functions include ReLU, sigmoid, and tanh.\n",
    "\n",
    "**Question 7: What is NORMALIZATION OF DATA?**\n",
    "\n",
    "Normalization involves scaling input data to have zero mean and unit variance. It helps stabilize and speed up training by preventing gradient explosion/vanishing and ensuring that different features contribute equally.\n",
    "\n",
    "**Question 8: What is IMAGE AUGMENTATION and how does it work?**\n",
    "\n",
    "Image augmentation is a data preprocessing technique that involves applying various transformations (rotations, flips, zooms) to training images. This increases dataset size, improves model generalization, and reduces overfitting.\n",
    "\n",
    "**Question 9: What is DECLINE IN LEARNING RATE?**\n",
    "\n",
    "Learning rate annealing, or a decline in learning rate, involves reducing the learning rate during training. This can help achieve better convergence by allowing larger steps initially and smaller steps as training progresses.\n",
    "\n",
    "**Question 10: What does EARLY STOPPING CRITERIA mean?**\n",
    "\n",
    "Early stopping criteria involve monitoring the model's performance on a validation set during training. If the performance plateaus or starts to degrade, training is stopped early to prevent overfitting and save computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a434c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
